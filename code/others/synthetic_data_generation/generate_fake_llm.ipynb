{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_files(root):\n",
    "    for root, dirs, files in os.walk(root):\n",
    "        for filename in files:\n",
    "            filename = os.path.join(root, filename)\n",
    "            if os.path.isfile(filename):  #or os.path.isdir(filename):  \n",
    "                yield filename          \n",
    "                # yield FileInfo(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(yield_files(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/jobs_full_duration_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/.~lock.new_death_info_good_format_columns.csv#',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/divorce_info_good_format_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/education_info_good_format_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/background_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/background_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/education_info_good_format_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/new_death_info_good_format_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/divorce_info_good_format_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/new_death_info_good_format_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/jobs_full_duration_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/new_death_info_good_format_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/divorce_info_good_format_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/jobs_full_duration_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/background_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/education_info_good_format_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_17_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_16_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_15_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_18_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_20_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_21_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_15_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_13_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_15_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_17_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_18_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_17_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_13_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_19_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_19_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_20_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_13_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_14_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_21_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_19_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_14_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_21_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_14_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_18_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_16_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_20_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly/income_16_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2020_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2012_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/.~lock.paycheck_2022_columns.csv#',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2018_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2014_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2020_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2017_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2013_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2022_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2021_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2013_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2015_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2019_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2015_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2018_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2016_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2023_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2016_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2017_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2022_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2021_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2021_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2018_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2012_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2019_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2015_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2020_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2023_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2022_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2016_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2013_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2012_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2014_meta.txt',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2014_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2019_columns.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2017_covariance.csv',\n",
       " '/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly/paycheck_2023_covariance.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "- this extracts all files\n",
    "- but we want only the unique file names \"path/filename.x\". Ie, strip off the \"columns\", \"covariance\", \"meta\" from the file name\n",
    "    - but we need this information to generate the fake data\n",
    "- thus, read in the unique file names, store the data from the three files (in a data class?)\n",
    "- data class vs function?\n",
    "    - dataclass nicer to work with than dict \n",
    "    - we can still create a function that generates the fake data and takes the data class as an input?\n",
    "- can we make this generalize to other data (the raw CBS data?) \n",
    "- also write tests for this?\n",
    "\n",
    "\n",
    "categorical variables can also be stored in integers. when should such a variable be generated as categorical?\n",
    "- problem is that we don't know the class probabilities \n",
    "- what is the cost of erring on one side or the other?\n",
    "    - is categorical but assume numerical -> \n",
    "    - is numerical but assume categorical \n",
    "- simple rule: if the q10 and q90 are below QMAX, assume categorical with equal distribution across classes \n",
    "- for municipality/age\n",
    "    - set QMAX = 10?\n",
    "    - I guess a more general rule is that there are not more than QMAX distinct integers between q10 and q90\n",
    "    - it is very unlikely to match q10 and q90 with a normal, given the mean and std \n",
    "    - we can fix this by adding some equal-weighted categoricals in some range [q10, x1] and [x2, q90]. \n",
    "    - how to determine x1 and x2? by chance, we may get min(generated) < q10, in which case nothing would happen\n",
    "        - instead, use x1 = q10(generated) and x2 = q90(generated)?\n",
    "    - for municipality, there will be negative draws -> replace them with 0, 1, or q10\n",
    "- for RINPERSOON (and other panel variables/PII variables): \n",
    "    - define base set of identifiers (1-100), then draw with random_choice\n",
    "        - this would be the preferred way, but we don't know if each row of PII variables are unique in a given dataframe or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_variable_type(row, max_diff_q10_q90=10):\n",
    "    \"\"\"Detect how a fake variable should be generated.\n",
    "\n",
    "    A column is detected as categorical if one of two conditions hold\n",
    "    - it has at least one category reported\n",
    "    - it is no category reported, but the summary statistics\n",
    "      imply only a limited number of possible classes.\n",
    "\n",
    "    Args:\n",
    "        row (dict): a row from a pd.DataFrame\n",
    "        max_diff_q10_q90 (int, optional): The maximum difference \n",
    "        between the 10th and 90th percentile in the empirical distribution.\n",
    "        This is used to infer the second case of categorical variables.\n",
    "\n",
    "    Returns:\n",
    "        dict: instructions to generate random variables.\n",
    "    \n",
    "    \"\"\"\n",
    "    category_0 = row[\"category_top_0\"]\n",
    "    if isinstance(category_0, str):\n",
    "        top_cats = [row[f\"category_top_{i}\"] for i in range(5)]\n",
    "        top_cats = [x for x in top_cats if isinstance(x, str)]\n",
    "        top_cats = [x.split(\"--\") for x in top_cats]\n",
    "        classes = [x[0] for x in top_cats]\n",
    "        probs = [float(x[1]) for x in top_cats]\n",
    "        result_dict = {\n",
    "            \"type\": \"categorical\",\n",
    "            \"classes\": classes,\n",
    "            \"probs\": probs\n",
    "        }\n",
    "    else:\n",
    "        p10, p90 = row[\"10th_percentile\"], row[\"90th_percentile\"]\n",
    "        if p90 - p10 <= max_diff_q10_q90:\n",
    "            # assert isinstance(p10, int) and isinstance(p90, int), \"assuming integers which is false\"\n",
    "            pdiff = int(p90) - int(p10)\n",
    "            # we want to include the end of the range, and deal with cases where p10=p90\n",
    "            addon = 1 if pdiff > 0 else 2\n",
    "            p90 += addon\n",
    "            pdiff += addon\n",
    "            result_dict = {\n",
    "                \"type\": \"categorical\",\n",
    "                \"classes\": np.arange(int(p10), int(p90)),\n",
    "                \"probs\": [1/pdiff for _ in range(pdiff)]\n",
    "            } \n",
    "        else:\n",
    "            result_dict = {\n",
    "                \"type\": \"continuous\",\n",
    "                \"mean\": row[\"mean\"],\n",
    "                \"std_dev\": row[\"std_dev\"],\n",
    "                \"min\": p10\n",
    "            }\n",
    "\n",
    "    result_dict[\"null_fraction\"] = row[\"null_fraction\"]\n",
    "    \n",
    "    return result_dict\n",
    "    \n",
    "# null fraction! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm', ['income_yearly', 'job_yearly'], ['jobs_full_duration_meta.txt', '.~lock.new_death_info_good_format_columns.csv#', 'divorce_info_good_format_covariance.csv', 'education_info_good_format_covariance.csv', 'background_columns.csv', 'background_meta.txt', 'education_info_good_format_columns.csv', 'new_death_info_good_format_meta.txt', 'divorce_info_good_format_meta.txt', 'new_death_info_good_format_columns.csv', 'jobs_full_duration_covariance.csv', 'new_death_info_good_format_covariance.csv', 'divorce_info_good_format_columns.csv', 'jobs_full_duration_columns.csv', 'background_covariance.csv', 'education_info_good_format_meta.txt'])\n",
      "('/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/income_yearly', [], ['income_17_columns.csv', 'income_16_columns.csv', 'income_15_covariance.csv', 'income_18_covariance.csv', 'income_20_meta.txt', 'income_21_columns.csv', 'income_15_columns.csv', 'income_13_columns.csv', 'income_15_meta.txt', 'income_17_meta.txt', 'income_18_columns.csv', 'income_17_covariance.csv', 'income_13_covariance.csv', 'income_19_columns.csv', 'income_19_covariance.csv', 'income_20_columns.csv', 'income_13_meta.txt', 'income_14_columns.csv', 'income_21_meta.txt', 'income_19_meta.txt', 'income_14_meta.txt', 'income_21_covariance.csv', 'income_14_covariance.csv', 'income_18_meta.txt', 'income_16_covariance.csv', 'income_20_covariance.csv', 'income_16_meta.txt'])\n",
      "('/home/flavio/OneDrive/NLeSC/Projects/2024_life2vec/stakeholders/CBS/exports/2024-05-14/data/llm/job_yearly', [], ['paycheck_2020_covariance.csv', 'paycheck_2012_columns.csv', '.~lock.paycheck_2022_columns.csv#', 'paycheck_2018_covariance.csv', 'paycheck_2014_columns.csv', 'paycheck_2020_meta.txt', 'paycheck_2017_columns.csv', 'paycheck_2013_columns.csv', 'paycheck_2022_meta.txt', 'paycheck_2021_meta.txt', 'paycheck_2013_meta.txt', 'paycheck_2015_meta.txt', 'paycheck_2019_meta.txt', 'paycheck_2015_covariance.csv', 'paycheck_2018_meta.txt', 'paycheck_2016_columns.csv', 'paycheck_2023_columns.csv', 'paycheck_2016_meta.txt', 'paycheck_2017_meta.txt', 'paycheck_2022_columns.csv', 'paycheck_2021_covariance.csv', 'paycheck_2021_columns.csv', 'paycheck_2018_columns.csv', 'paycheck_2012_meta.txt', 'paycheck_2019_covariance.csv', 'paycheck_2015_columns.csv', 'paycheck_2020_columns.csv', 'paycheck_2023_meta.txt', 'paycheck_2022_covariance.csv', 'paycheck_2016_covariance.csv', 'paycheck_2013_covariance.csv', 'paycheck_2012_covariance.csv', 'paycheck_2014_meta.txt', 'paycheck_2014_covariance.csv', 'paycheck_2019_columns.csv', 'paycheck_2017_covariance.csv', 'paycheck_2023_covariance.csv'])\n"
     ]
    }
   ],
   "source": [
    "files = os.walk(url)\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main data class we are working with -- **give it a better name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataSummary: # TODO: give better name\n",
    "    \"\"\"Class to read summary files from CBS.\n",
    "\n",
    "    Arguments:\n",
    "        url: local path where the summary files are stored\n",
    "        filename: the name of the original data file \n",
    "    \"\"\"\n",
    "    url: str \n",
    "    filename: str \n",
    "\n",
    "\n",
    "    def load(self):\n",
    "        \"Load meta data and column summaries\"\n",
    "        with open(os.path.join(self.url, self.filename + \"_meta.txt\"), \"r\") as f:\n",
    "            self.meta = dict(json.load(f))\n",
    "        \n",
    "        self.col_summary = pd.read_csv(os.path.join(self.url, self.filename + \"_columns.csv\"))\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Process metadata and summary statistics to define how each column should be generated.\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for _, row in self.col_summary.iterrows():\n",
    "            variable = row[\"variable_name\"]\n",
    "            results[variable] = detect_variable_type(row)\n",
    "        \n",
    "        self.generation_inputs = results\n",
    "\n",
    "\n",
    "    def generate(self, rng, size=None):\n",
    "        \"\"\"Generate new data while\n",
    "            - enforcing non-negativity of numerical variables\n",
    "            - considering PII columns: each column is an integer range from 0 to `size`. \n",
    "            - considering null fractions\n",
    "        \n",
    "        Args:\n",
    "            rng (np.random.default_rng): random number generator\n",
    "            n (int, optional): Size of sample to generate. If `None`, the size is taken from\n",
    "            the data summary.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: the generated data\n",
    "        \"\"\"\n",
    "        assert self.generation_inputs, \"You need to `fit` before calling `generate`.\"\n",
    "        if size is None:\n",
    "            size = self.meta.get(\"total_nobs\")\n",
    "        column_dtypes = self.meta.get(\"columns_with_dtypes\")\n",
    "\n",
    "        data = {}\n",
    "\n",
    "        pii_cols = self.meta.get(\"has_pii_columns\")\n",
    "        for pc in pii_cols:\n",
    "            data[pc] = np.arange(size)\n",
    "\n",
    "        for colname, inputs in self.generation_inputs.items(): \n",
    "            # TODO -- put this check into a function      \n",
    "            required_dtype = column_dtypes.get(colname)\n",
    "            implemented_types = [\"object\", \"int64\"]\n",
    "            if required_dtype not in implemented_types:\n",
    "                raise NotImplementedError(\"data type %s not implemented\" % required_dtype)\n",
    "        \n",
    "            n_nulls = int(size * inputs[\"null_fraction\"])\n",
    "            n_nonulls = size - n_nulls \n",
    "\n",
    "            if inputs[\"type\"] == \"categorical\":\n",
    "                col_data = rng.choice(a=inputs[\"classes\"], size=n_nonulls, p=inputs[\"probs\"])\n",
    "            elif inputs[\"type\"] == \"continuous\":\n",
    "                col_data = rng.normal(inputs[\"mean\"], inputs[\"std_dev\"], n_nonulls)\n",
    "                min_value = inputs[\"min\"]\n",
    "                negatives = np.where(col_data < 0)\n",
    "                col_data[negatives] = min_value\n",
    "                if required_dtype == \"int64\":\n",
    "                    col_data = np.int64(np.round(col_data))\n",
    "\n",
    "            nulls = np.tile(np.nan, n_nulls)\n",
    "            col_data = np.concatenate([nulls, col_data])\n",
    "            rng.shuffle(col_data)\n",
    "\n",
    "            data[colname] = col_data\n",
    "\n",
    "        return pd.DataFrame(data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_full_duration = DataSummary(url=url, filename=\"jobs_full_duration\")\n",
    "jobs_full_duration.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/gpfs/ostor/ossc9424/homedir/Tanzir/LifeToVec_Nov/projects//dutch_real/data/jobs_full_duration.csv',\n",
       " 'shape': [27288936, 11],\n",
       " 'columns_with_dtypes': {'RINPERSOON': 'int64',\n",
       "  'age': 'int64',\n",
       "  'daysSinceFirstEvent': 'int64',\n",
       "  'contractType2': 'int64',\n",
       "  'sicknessInsurance2': 'int64',\n",
       "  'fullTime2': 'int64',\n",
       "  'sector2': 'int64',\n",
       "  'industry2': 'int64',\n",
       "  'jobType2': 'int64',\n",
       "  'empRelationship2': 'int64',\n",
       "  'begOrEnd': 'int64'},\n",
       " 'total_nobs': 27288936,\n",
       " 'nobs_sumstat': None,\n",
       " 'has_pii_columns': ['RINPERSOON']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_full_duration.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>10th_percentile</th>\n",
       "      <th>90th_percentile</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "      <th>null_fraction</th>\n",
       "      <th>category_top_0</th>\n",
       "      <th>category_top_1</th>\n",
       "      <th>category_top_2</th>\n",
       "      <th>category_top_3</th>\n",
       "      <th>category_top_4</th>\n",
       "      <th>_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.692786</td>\n",
       "      <td>5.121164</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daysSinceFirstEvent</td>\n",
       "      <td>16076.0</td>\n",
       "      <td>16261.625102</td>\n",
       "      <td>1452.578314</td>\n",
       "      <td>14397.0</td>\n",
       "      <td>18507.0</td>\n",
       "      <td>14977.0</td>\n",
       "      <td>17472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contractType2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.685221</td>\n",
       "      <td>0.945901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sicknessInsurance2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.036220</td>\n",
       "      <td>0.186836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fullTime2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.593243</td>\n",
       "      <td>0.491229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sector2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.486110</td>\n",
       "      <td>1.164521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>industry2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.494275</td>\n",
       "      <td>20.903393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jobType2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.672533</td>\n",
       "      <td>1.054801</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>empRelationship2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.748129</td>\n",
       "      <td>5.093709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>begOrEnd</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variable_name   median          mean      std_dev  10th_percentile  \\\n",
       "0                  age     28.0     28.692786     5.121164             22.0   \n",
       "1  daysSinceFirstEvent  16076.0  16261.625102  1452.578314          14397.0   \n",
       "2        contractType2      1.0      1.685221     0.945901              1.0   \n",
       "3   sicknessInsurance2      1.0      1.036220     0.186836              1.0   \n",
       "4            fullTime2      2.0      1.593243     0.491229              1.0   \n",
       "5              sector2      1.0      1.486110     1.164521              1.0   \n",
       "6            industry2     36.0     30.494275    20.903393              1.0   \n",
       "7             jobType2      5.0      4.672533     1.054801              5.0   \n",
       "8     empRelationship2      1.0      3.748129     5.093709              1.0   \n",
       "9             begOrEnd      1.5      1.500000     0.500000              1.0   \n",
       "\n",
       "   90th_percentile       q1       q3  null_fraction  category_top_0  \\\n",
       "0             36.0     25.0     32.0            0.0             NaN   \n",
       "1          18507.0  14977.0  17472.0            0.0             NaN   \n",
       "2              3.0      1.0      3.0            0.0             NaN   \n",
       "3              1.0      1.0      1.0            0.0             NaN   \n",
       "4              2.0      1.0      2.0            0.0             NaN   \n",
       "5              2.0      1.0      1.0            0.0             NaN   \n",
       "6             55.0     10.0     46.0            0.0             NaN   \n",
       "7              5.0      5.0      5.0            0.0             NaN   \n",
       "8             11.0      1.0      7.0            0.0             NaN   \n",
       "9              2.0      1.0      2.0            0.0             NaN   \n",
       "\n",
       "   category_top_1  category_top_2  category_top_3  category_top_4  _others  \n",
       "0             NaN             NaN             NaN             NaN      NaN  \n",
       "1             NaN             NaN             NaN             NaN      NaN  \n",
       "2             NaN             NaN             NaN             NaN      NaN  \n",
       "3             NaN             NaN             NaN             NaN      NaN  \n",
       "4             NaN             NaN             NaN             NaN      NaN  \n",
       "5             NaN             NaN             NaN             NaN      NaN  \n",
       "6             NaN             NaN             NaN             NaN      NaN  \n",
       "7             NaN             NaN             NaN             NaN      NaN  \n",
       "8             NaN             NaN             NaN             NaN      NaN  \n",
       "9             NaN             NaN             NaN             NaN      NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_full_duration.col_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_full_duration.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rng = np.random.default_rng(seed=99303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = jobs_full_duration.generate(rng=my_rng, size=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RINPERSOON</th>\n",
       "      <th>age</th>\n",
       "      <th>daysSinceFirstEvent</th>\n",
       "      <th>contractType2</th>\n",
       "      <th>sicknessInsurance2</th>\n",
       "      <th>fullTime2</th>\n",
       "      <th>sector2</th>\n",
       "      <th>industry2</th>\n",
       "      <th>jobType2</th>\n",
       "      <th>empRelationship2</th>\n",
       "      <th>begOrEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>499.500000</td>\n",
       "      <td>28.579000</td>\n",
       "      <td>16204.472000</td>\n",
       "      <td>1.989000</td>\n",
       "      <td>1.513000</td>\n",
       "      <td>1.495000</td>\n",
       "      <td>1.497000</td>\n",
       "      <td>31.307000</td>\n",
       "      <td>5.521000</td>\n",
       "      <td>5.981000</td>\n",
       "      <td>1.483000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288.819436</td>\n",
       "      <td>5.240727</td>\n",
       "      <td>1490.877172</td>\n",
       "      <td>0.813351</td>\n",
       "      <td>0.500081</td>\n",
       "      <td>0.500225</td>\n",
       "      <td>0.500241</td>\n",
       "      <td>19.524906</td>\n",
       "      <td>0.499809</td>\n",
       "      <td>3.130565</td>\n",
       "      <td>0.499961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11691.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>249.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15212.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>499.500000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>16162.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>749.250000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>17262.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>20660.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RINPERSOON          age  daysSinceFirstEvent  contractType2  \\\n",
       "count  1000.000000  1000.000000          1000.000000    1000.000000   \n",
       "mean    499.500000    28.579000         16204.472000       1.989000   \n",
       "std     288.819436     5.240727          1490.877172       0.813351   \n",
       "min       0.000000    12.000000         11691.000000       1.000000   \n",
       "25%     249.750000    25.000000         15212.000000       1.000000   \n",
       "50%     499.500000    29.000000         16162.000000       2.000000   \n",
       "75%     749.250000    32.000000         17262.000000       3.000000   \n",
       "max     999.000000    46.000000         20660.000000       3.000000   \n",
       "\n",
       "       sicknessInsurance2    fullTime2      sector2    industry2     jobType2  \\\n",
       "count         1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean             1.513000     1.495000     1.497000    31.307000     5.521000   \n",
       "std              0.500081     0.500225     0.500241    19.524906     0.499809   \n",
       "min              1.000000     1.000000     1.000000     0.000000     5.000000   \n",
       "25%              1.000000     1.000000     1.000000    16.750000     5.000000   \n",
       "50%              2.000000     1.000000     1.000000    31.000000     6.000000   \n",
       "75%              2.000000     2.000000     2.000000    44.000000     6.000000   \n",
       "max              2.000000     2.000000     2.000000   110.000000     6.000000   \n",
       "\n",
       "       empRelationship2     begOrEnd  \n",
       "count       1000.000000  1000.000000  \n",
       "mean           5.981000     1.483000  \n",
       "std            3.130565     0.499961  \n",
       "min            1.000000     1.000000  \n",
       "25%            3.000000     1.000000  \n",
       "50%            6.000000     1.000000  \n",
       "75%            9.000000     2.000000  \n",
       "max           11.000000     2.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to iterate the above across all files -- tbd\n",
    "- also, for the raw CBS files, we need to define which years we want to generate the data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file = \"new_death_info_good_format\"\n",
    "meta = current_file + \"_meta.txt\"\n",
    "covariance = current_file + \"_covariance.csv\"\n",
    "columns = current_file + \"_columns.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(url, meta), \"r\") as f:\n",
    "    metadata = dict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/gpfs/ostor/ossc9424/homedir/Tanzir/LifeToVec_Nov/projects//dutch_real/data/new_death_info_good_format.csv',\n",
       " 'shape': [4316610, 4],\n",
       " 'columns_with_dtypes': {'RINPERSOON': 'int64',\n",
       "  'daysSinceFirstEvent': 'int64',\n",
       "  'age': 'int64',\n",
       "  '[DEATH]': 'object'},\n",
       " 'total_nobs': 4316610,\n",
       " 'nobs_sumstat': None,\n",
       " 'has_pii_columns': ['RINPERSOON']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>10th_percentile</th>\n",
       "      <th>90th_percentile</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "      <th>null_fraction</th>\n",
       "      <th>category_top_0</th>\n",
       "      <th>category_top_1</th>\n",
       "      <th>category_top_2</th>\n",
       "      <th>category_top_3</th>\n",
       "      <th>category_top_4</th>\n",
       "      <th>_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daysSinceFirstEvent</td>\n",
       "      <td>13992.0</td>\n",
       "      <td>1.384631e+04</td>\n",
       "      <td>3.096643e+03</td>\n",
       "      <td>9462.9</td>\n",
       "      <td>17969.0</td>\n",
       "      <td>11133.0</td>\n",
       "      <td>16607.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-5.769135e+14</td>\n",
       "      <td>7.294350e+16</td>\n",
       "      <td>57.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[DEATH]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D--1.0</td>\n",
       "      <td>EMPTY--0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variable_name   median          mean       std_dev  10th_percentile  \\\n",
       "0  daysSinceFirstEvent  13992.0  1.384631e+04  3.096643e+03           9462.9   \n",
       "1                  age     80.0 -5.769135e+14  7.294350e+16             57.0   \n",
       "2              [DEATH]      NaN           NaN           NaN              NaN   \n",
       "\n",
       "   90th_percentile       q1       q3  null_fraction category_top_0  \\\n",
       "0          17969.0  11133.0  16607.0            0.0            NaN   \n",
       "1             92.0     70.0     87.0            0.0            NaN   \n",
       "2              NaN      NaN      NaN            0.0         D--1.0   \n",
       "\n",
       "  category_top_1  category_top_2  category_top_3  category_top_4  _others  \n",
       "0            NaN             NaN             NaN             NaN      NaN  \n",
       "1            NaN             NaN             NaN             NaN      NaN  \n",
       "2     EMPTY--0.0             NaN             NaN             NaN      0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_cols = pd.read_csv(os.path.join(url, columns))\n",
    "d_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(1.0) == 1.0\n",
    "isinstance(1.0, np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=5958375235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1258.0\n",
      "1846.0\n"
     ]
    }
   ],
   "source": [
    "testdraws = np.round(rng.normal(loc=345, scale=328, size=100_000))\n",
    "print(testdraws.min())\n",
    "print(testdraws.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-418., 1111.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanpercentile(testdraws, [1, 99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "choice(a, size=None, replace=True, p=None, axis=0, shuffle=True)\n",
      "\n",
      "Generates a random sample from a given array\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "a : {array_like, int}\n",
      "    If an ndarray, a random sample is generated from its elements.\n",
      "    If an int, the random sample is generated from np.arange(a).\n",
      "size : {int, tuple[int]}, optional\n",
      "    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "    ``m * n * k`` samples are drawn from the 1-d `a`. If `a` has more\n",
      "    than one dimension, the `size` shape will be inserted into the\n",
      "    `axis` dimension, so the output ``ndim`` will be ``a.ndim - 1 +\n",
      "    len(size)``. Default is None, in which case a single value is\n",
      "    returned.\n",
      "replace : bool, optional\n",
      "    Whether the sample is with or without replacement. Default is True,\n",
      "    meaning that a value of ``a`` can be selected multiple times.\n",
      "p : 1-D array_like, optional\n",
      "    The probabilities associated with each entry in a.\n",
      "    If not given, the sample assumes a uniform distribution over all\n",
      "    entries in ``a``.\n",
      "axis : int, optional\n",
      "    The axis along which the selection is performed. The default, 0,\n",
      "    selects by row.\n",
      "shuffle : bool, optional\n",
      "    Whether the sample is shuffled when sampling without replacement.\n",
      "    Default is True, False provides a speedup.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "samples : single item or ndarray\n",
      "    The generated random samples\n",
      "\n",
      "Raises\n",
      "------\n",
      "ValueError\n",
      "    If a is an int and less than zero, if p is not 1-dimensional, if\n",
      "    a is array-like with a size 0, if p is not a vector of\n",
      "    probabilities, if a and p have different lengths, or if\n",
      "    replace=False and the sample size is greater than the population\n",
      "    size.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "integers, shuffle, permutation\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Setting user-specified probabilities through ``p`` uses a more general but less\n",
      "efficient sampler than the default. The general sampler produces a different sample\n",
      "than the optimized sampler even if each element of ``p`` is 1 / len(a).\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Generate a uniform random sample from np.arange(5) of size 3:\n",
      "\n",
      ">>> rng = np.random.default_rng()\n",
      ">>> rng.choice(5, 3)\n",
      "array([0, 3, 4]) # random\n",
      ">>> #This is equivalent to rng.integers(0,5,3)\n",
      "\n",
      "Generate a non-uniform random sample from np.arange(5) of size 3:\n",
      "\n",
      ">>> rng.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "array([3, 3, 0]) # random\n",
      "\n",
      "Generate a uniform random sample from np.arange(5) of size 3 without\n",
      "replacement:\n",
      "\n",
      ">>> rng.choice(5, 3, replace=False)\n",
      "array([3,1,0]) # random\n",
      ">>> #This is equivalent to rng.permutation(np.arange(5))[:3]\n",
      "\n",
      "Generate a uniform random sample from a 2-D array along the first\n",
      "axis (the default), without replacement:\n",
      "\n",
      ">>> rng.choice([[0, 1, 2], [3, 4, 5], [6, 7, 8]], 2, replace=False)\n",
      "array([[3, 4, 5], # random\n",
      "       [0, 1, 2]])\n",
      "\n",
      "Generate a non-uniform random sample from np.arange(5) of size\n",
      "3 without replacement:\n",
      "\n",
      ">>> rng.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "array([2, 3, 0]) # random\n",
      "\n",
      "Any of the above can be repeated with an arbitrary array-like\n",
      "instead of just integers. For instance:\n",
      "\n",
      ">>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
      ">>> rng.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])\n",
      "array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'], # random\n",
      "      dtype='<U11')\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "?rng.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "normal(loc=0.0, scale=1.0, size=None)\n",
      "\n",
      "Draw random samples from a normal (Gaussian) distribution.\n",
      "\n",
      "The probability density function of the normal distribution, first\n",
      "derived by De Moivre and 200 years later by both Gauss and Laplace\n",
      "independently [2]_, is often called the bell curve because of\n",
      "its characteristic shape (see the example below).\n",
      "\n",
      "The normal distributions occurs often in nature.  For example, it\n",
      "describes the commonly occurring distribution of samples influenced\n",
      "by a large number of tiny, random disturbances, each with its own\n",
      "unique distribution [2]_.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "loc : float or array_like of floats\n",
      "    Mean (\"centre\") of the distribution.\n",
      "scale : float or array_like of floats\n",
      "    Standard deviation (spread or \"width\") of the distribution. Must be\n",
      "    non-negative.\n",
      "size : int or tuple of ints, optional\n",
      "    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "    ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "    a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "    Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "out : ndarray or scalar\n",
      "    Drawn samples from the parameterized normal distribution.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "scipy.stats.norm : probability density function, distribution or\n",
      "    cumulative density function, etc.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The probability density for the Gaussian distribution is\n",
      "\n",
      ".. math:: p(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n",
      "                 e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} },\n",
      "\n",
      "where :math:`\\mu` is the mean and :math:`\\sigma` the standard\n",
      "deviation. The square of the standard deviation, :math:`\\sigma^2`,\n",
      "is called the variance.\n",
      "\n",
      "The function has its peak at the mean, and its \"spread\" increases with\n",
      "the standard deviation (the function reaches 0.607 times its maximum at\n",
      ":math:`x + \\sigma` and :math:`x - \\sigma` [2]_).  This implies that\n",
      ":meth:`normal` is more likely to return samples lying close to the\n",
      "mean, rather than those far away.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] Wikipedia, \"Normal distribution\",\n",
      "       https://en.wikipedia.org/wiki/Normal_distribution\n",
      ".. [2] P. R. Peebles Jr., \"Central Limit Theorem\" in \"Probability,\n",
      "       Random Variables and Random Signal Principles\", 4th ed., 2001,\n",
      "       pp. 51, 51, 125.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "Draw samples from the distribution:\n",
      "\n",
      ">>> mu, sigma = 0, 0.1 # mean and standard deviation\n",
      ">>> s = np.random.default_rng().normal(mu, sigma, 1000)\n",
      "\n",
      "Verify the mean and the variance:\n",
      "\n",
      ">>> abs(mu - np.mean(s))\n",
      "0.0  # may vary\n",
      "\n",
      ">>> abs(sigma - np.std(s, ddof=1))\n",
      "0.0  # may vary\n",
      "\n",
      "Display the histogram of the samples, along with\n",
      "the probability density function:\n",
      "\n",
      ">>> import matplotlib.pyplot as plt\n",
      ">>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
      ">>> plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
      "...                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
      "...          linewidth=2, color='r')\n",
      ">>> plt.show()\n",
      "\n",
      "Two-by-four array of samples from the normal distribution with\n",
      "mean 3 and standard deviation 2.5:\n",
      "\n",
      ">>> np.random.default_rng().normal(3, 2.5, size=(2, 4))\n",
      "array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n",
      "       [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "?rng.normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
